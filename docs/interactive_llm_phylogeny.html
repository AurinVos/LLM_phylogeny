<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <title>LLM Phylogeny</title>
    <style>
      html, body {
        box-sizing: border-box;
        display: flow-root;
        height: 100%;
        margin: 0;
        padding: 0;
      }
    </style>
<script type="text/javascript" src="https://cdn.bokeh.org/bokeh/release/bokeh-3.8.0.min.js"></script>
<script type="text/javascript" src="https://cdn.bokeh.org/bokeh/release/bokeh-widgets-3.8.0.min.js"></script>
<script type="text/javascript">
Bokeh.set_log_level("info");
</script>
  </head>
  <body>
    <div id="ff62c9fe-89c9-4684-be4f-5f65d6ec9cba" data-root-id="p1006" style="display: contents;"></div>
  
    <script type="application/json" id="d0573749-d46c-466a-b8e8-a2f82dbce74e">
      {"6495d2a5-46b1-428e-98d5-918922097422":{"version":"3.8.0","title":"Bokeh Application","config":{"type":"object","name":"DocumentConfig","id":"p1009","attributes":{"notifications":{"type":"object","name":"Notifications","id":"p1010"}}},"roots":[{"type":"object","name":"Div","id":"p1006","attributes":{"width":1200,"height":800,"text":"<div id=\"three-phylogeny-61a1376911a9415f91efca16daf4b784\" class=\"three-phylogeny-container\" style=\"width:100%;height:100%;\"></div>"}}]}}
    </script>
    <script type="text/javascript">
      (function() {
        const fn = function() {
          Bokeh.safely(function() {
            (function(root) {
              function embed_document(root) {
              const docs_json = document.getElementById('d0573749-d46c-466a-b8e8-a2f82dbce74e').textContent;
              const render_items = [{"docid":"6495d2a5-46b1-428e-98d5-918922097422","roots":{"p1006":"ff62c9fe-89c9-4684-be4f-5f65d6ec9cba"},"root_ids":["p1006"]}];
              root.Bokeh.embed.embed_items(docs_json, render_items);
              }
              if (root.Bokeh !== undefined) {
                embed_document(root);
              } else {
                let attempts = 0;
                const timer = setInterval(function(root) {
                  if (root.Bokeh !== undefined) {
                    clearInterval(timer);
                    embed_document(root);
                  } else {
                    attempts++;
                    if (attempts > 100) {
                      clearInterval(timer);
                      console.log("Bokeh: ERROR: Unable to run BokehJS code because BokehJS library is missing");
                    }
                  }
                }, 10, root)
              }
            })(window);
          });
        };
        if (document.readyState != "loading") fn();
        else document.addEventListener("DOMContentLoaded", fn);
      })();
    </script>
  <script type="text/javascript">

(function() {
  const CONFIG = {"data": {"x": [0.0, 365.0, 487.0, 579.0, 610.0, 730.0, 760.0, 791.0, 822.0, 852.0, 852.0, 1004.0, 1065.0, 1310.0, 1430.0, 1644.0, 1644.0, 1675.0, 1734.0, 1765.0, 1795.0, 1795.0, 1856.0, 2009.0, 2071.0, 2099.0, 2099.0, 2191.0, 2221.0, 2221.0, 2221.0, 2252.0, 2252.0, 2283.0, 2283.0, 2344.0, 2344.0, 2374.0, 2405.0, 2405.0, 2436.0, 2465.0, 2465.0, 2465.0, 2496.0, 2526.0, 2557.0, 2557.0, 2587.0, 2649.0, 2679.0, 2740.0, 2771.0, 2771.0, 2802.0, 2861.0, 2891.0, 2891.0, 2983.0, 2983.0, 3014.0], "y": [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0, 16.0, 17.0, 18.0, 19.0, 20.0, 21.0, 22.0, 23.0, 24.0, 25.0, 26.0, 27.0, 28.0, 29.0, 30.0, 31.0, 32.0, 33.0, 34.0, 35.0, 36.0, 37.0, 38.0, 39.0, 40.0, 41.0, 42.0, 43.0, 44.0, 45.0, 46.0, 47.0, 48.0, 49.0, 50.0, 51.0, 52.0, 53.0, 54.0, 55.0, 56.0, 57.0, 58.0, 59.0, 60.0], "z": [24.0, 2.0, 4.0, 49.0, 47.0, 42.0, 39.0, 34.0, 40.0, 9.0, 56.0, 45.0, 0.0, 53.0, 10.0, 48.0, 19.0, 44.0, 8.0, 41.0, 31.0, 46.0, 36.0, 50.0, 12.0, 27.0, 1.0, 5.0, 13.0, 38.0, 58.0, 28.0, 6.0, 51.0, 22.0, 20.0, 3.0, 52.0, 25.0, 11.0, 32.0, 15.0, 30.0, 17.0, 57.0, 60.0, 23.0, 7.0, 35.0, 54.0, 16.0, 59.0, 14.0, 43.0, 29.0, 33.0, 55.0, 18.0, 37.0, 26.0, 21.0], "color": ["#c7c7c7", "#d62728", "#98df8a", "#8c564b", "#d62728", "#98df8a", "#98df8a", "#bcbd22", "#98df8a", "#dbdb8d", "#dbdb8d", "#98df8a", "#d62728", "#e377c2", "#ff9896", "#ffbb78", "#e377c2", "#1f77b4", "#ffbb78", "#ff9896", "#dbdb8d", "#f7b6d2", "#f7b6d2", "#1f77b4", "#c5b0d5", "#d62728", "#ff7f0e", "#aec7e8", "#ff7f0e", "#c5b0d5", "#9467bd", "#ff7f0e", "#7f7f7f", "#c49c94", "#aec7e8", "#ff7f0e", "#17becf", "#c49c94", "#9467bd", "#aec7e8", "#ff9896", "#ff7f0e", "#ff7f0e", "#ff7f0e", "#c5b0d5", "#d62728", "#ff7f0e", "#7f7f7f", "#c5b0d5", "#2ca02c", "#ff7f0e", "#2ca02c", "#7f7f7f", "#2ca02c", "#ff7f0e", "#7f7f7f", "#ff7f0e", "#ff7f0e", "#d62728", "#ff7f0e", "#ff7f0e"], "name": ["Attention Is All You Need", "GPT-1", "BERT", "Transformer-XL", "GPT-2", "XLNet", "RoBERTa", "Megatron-LM", "ALBERT", "BART", "T5", "ELECTRA", "GPT-3", "Switch Transformer", "LaMDA", "Gopher", "GLaM", "InstructGPT", "Chinchilla", "PaLM", "UL2", "OPT", "BLOOM", "Constitutional AI", "LLaMA", "GPT-4", "Claude 1", "Baichuan-7B", "Claude 2", "Llama 2", "InternLM-7B", "Claude Instant 1.2", "Qwen 7B", "Mistral 7B", "Baichuan2", "Claude 2.1", "Yi-34B", "Mixtral 8x7B", "InternLM2-7B", "Baichuan3", "Gemini 1.5", "Claude 3 Haiku", "Claude 3 Sonnet", "Claude 3 Opus", "Llama 3", "GPT-4o", "Claude 3.5 Sonnet", "Qwen2", "Llama 3.1", "DeepSeek-V2.5", "Claude 3.5 Haiku", "DeepSeek-V3", "Qwen2.5 (Max)", "DeepSeek-R1", "Claude 3.7 Sonnet", "Qwen3", "Claude 4 Sonnet", "Claude 4 Opus", "GPT-5", "Claude Opus 4.1", "Claude 4.5 Sonnet"], "family": ["Root", "GPT", "Encoder-only", "Long-context", "GPT", "Encoder-only", "Encoder-only", "Scaling", "Encoder-only", "Seq2Seq", "Seq2Seq", "Encoder-only", "GPT", "Mixture-of-Experts", "Google", "DeepMind/Scaling", "Mixture-of-Experts", "Alignment", "DeepMind/Scaling", "Google", "Seq2Seq", "Open-Source GPT", "Open-Source GPT", "Alignment", "LLaMA", "GPT", "Claude", "Baichuan", "Claude", "LLaMA", "InternLM", "Claude", "Qwen", "Mistral", "Baichuan", "Claude", "Yi", "Mistral", "InternLM", "Baichuan", "Google", "Claude", "Claude", "Claude", "LLaMA", "GPT", "Claude", "Qwen", "LLaMA", "DeepSeek", "Claude", "DeepSeek", "Qwen", "DeepSeek", "Claude", "Qwen", "Claude", "Claude", "GPT", "Claude", "Claude"], "release": ["Jun 2017", "Jun 2018", "Oct 2018", "Jan 2019", "Feb 2019", "Jun 2019", "Jul 2019", "Aug 2019", "Sep 2019", "Oct 2019", "Oct 2019", "Mar 2020", "May 2020", "Jan 2021", "May 2021", "Dec 2021", "Dec 2021", "Jan 2022", "Mar 2022", "Apr 2022", "May 2022", "May 2022", "Jul 2022", "Dec 2022", "Feb 2023", "Mar 2023", "Mar 2023", "Jun 2023", "Jul 2023", "Jul 2023", "Jul 2023", "Aug 2023", "Aug 2023", "Sep 2023", "Sep 2023", "Nov 2023", "Nov 2023", "Dec 2023", "Jan 2024", "Jan 2024", "Feb 2024", "Mar 2024", "Mar 2024", "Mar 2024", "Apr 2024", "May 2024", "Jun 2024", "Jun 2024", "Jul 2024", "Sep 2024", "Oct 2024", "Dec 2024", "Jan 2025", "Jan 2025", "Feb 2025", "Apr 2025", "May 2025", "May 2025", "Aug 2025", "Aug 2025", "Sep 2025"], "innovation": ["Introduced the Transformer architecture with multi-head self-attention and positional encoding", "Applied decoder-only Transformer with generative pretraining on BooksCorpus", "Bidirectional encoder pretraining with masked language modelling and next sentence prediction", "Segment-level recurrence and relative positional encoding for long-context modelling", "Scaled decoder-only models with zero-shot transfer via WebText", "Permuted language modelling objective blending autoregressive and autoencoding pretraining", "Optimised masked language modelling with longer training, dynamic masking, and larger batches", "Model parallelism for trillion-parameter scale using tensor and pipeline parallelism", "Parameter sharing and factorised embeddings for lightweight bidirectional transformers", "Denoising autoencoder that bridges encoder-decoder pretraining for text generation", "Text-to-Text framework with unified transfer learning and span-corruption objective", "Replaced masked language modelling with discriminator that detects replaced tokens", "175B parameter scaling with in-context learning across diverse tasks", "Sparse mixture-of-experts routing enabling trillion-parameter efficiency", "Dialogue-optimised training with safety fine-tuning and grounded responses", "Scaling laws with retrieval-style evaluation and precision study for large transformers", "Hierarchical mixture-of-experts with token-level routing across 1.2T parameters", "Reinforcement learning from human feedback tailored to instruction following", "Data/parameter scaling law balancing showing benefits of more tokens over parameters", "Pathways system with parallelism and chain-of-thought prompting across 540B parameters", "Mixture-of-denoisers objective supporting multiple corruption schemes for unified learning", "Reproducible GPT-3 class model with fully documented training pipeline", "Multilingual open-access 176B parameter model trained collaboratively via Megatron-DeepSpeed", "Self-critiquing alignment loop guided by explicit normative principles", "Efficient scaling via smaller datasets, grouped-query attention, and open research weights", "Large multimodal alignment with reinforced fine-tuning and tool integration", "Applied constitutional AI feedback to align helpful and harmless behaviour", "Chinese-English bilingual adaptation of LLaMA with extended vocabulary", "Expanded context and constitutional alignment refinements with tool use", "Open-weight release with supervised fine-tuning and RLHF safety tuning", "Toolkit-oriented Chinese open model with multi-stage pretraining and alignment", "Latency-optimised Claude variant retaining constitutional safety guarantees", "Chinese-English foundation with rotary embeddings and fine-grained tokeniser", "Sliding window attention and grouped-query attention for efficient small models", "Improved bilingual data curation with extended context and tool APIs", "Higher factual reliability and longer context for enterprise tasks", "Balanced bilingual dataset with progressive context extension", "Sparse mixture-of-experts combining eight Mistral experts with router training", "Iterative distillation with modular tool-using skills and expanded context", "Domain-adaptive pretraining with knowledge-augmented decoding", "Mixture-of-experts multimodal model with million-token context", "Fast multimodal assistant with revised constitutional tuning", "Mid-tier multimodal reasoning with tool orchestration", "Flagship Claude with state-of-the-art reasoning and coding alignment", "Token-efficient vocabulary and speculatively decoded training mix", "Unified multimodal end-to-end model with real-time streaming latency", "Improved tool-use reliability and creative reasoning", "Data mixture refresh with extended context and reasoning tuning", "Multi-token prediction and improved tool-calling APIs", "Sparse mixture-of-experts with hybrid reinforcement learning", "Faster multimodal responses with improved grounding", "Unified MoE and dense experts with reinforcement fine-tuning", "Expanded multilingual coverage with large context generalisation", "Reinforced reasoning with reward models targeting mathematical proofs", "Long-context orchestration and improved agentic behaviours", "Mixture-of-experts scaling with automated reasoning curriculum", "Structured tool-use planning with autonomous memory", "Frontier reasoning with multi-agent constitutional guidance", "Next-generation multimodal orchestration with autonomous tool chains", "Iterative self-improvement through agentic evaluation loops", "Hybrid symbolic-neural planning with compressed memory"], "influences": ["None", "Attention Is All You Need", "Attention Is All You Need", "Attention Is All You Need", "GPT-1", "Transformer-XL, BERT", "BERT", "GPT-2", "BERT", "Attention Is All You Need", "Attention Is All You Need", "BERT", "GPT-2", "T5", "Attention Is All You Need", "Attention Is All You Need", "Switch Transformer", "GPT-3", "Gopher", "LaMDA", "T5", "GPT-3", "GPT-3, Megatron-LM", "InstructGPT", "Chinchilla", "Chinchilla, GPT-3", "Constitutional AI", "LLaMA", "Claude 1", "LLaMA", "LLaMA", "Claude 1", "Chinchilla, LLaMA", "Chinchilla, LLaMA", "Baichuan-7B", "Claude 2", "Llama 2", "Mistral 7B", "InternLM-7B", "Baichuan2", "PaLM", "Claude 2.1", "Claude 2.1", "Claude 2.1", "Llama 2", "GPT-4", "Claude 3 Sonnet", "Qwen 7B", "Llama 3", "LLaMA", "Claude 3 Haiku", "DeepSeek-V2.5", "Qwen2", "DeepSeek-V3", "Claude 3.5 Sonnet", "Qwen2.5 (Max)", "Claude 3.7 Sonnet", "Claude 3 Opus", "GPT-4o", "Claude 4 Opus", "Claude 4 Sonnet"]}, "edges": [{"x0": 0.0, "y0": 0.0, "z0": 24.0, "x1": 365.0, "y1": 1.0, "z1": 2.0}, {"x0": 0.0, "y0": 0.0, "z0": 24.0, "x1": 487.0, "y1": 2.0, "z1": 4.0}, {"x0": 0.0, "y0": 0.0, "z0": 24.0, "x1": 579.0, "y1": 3.0, "z1": 49.0}, {"x0": 0.0, "y0": 0.0, "z0": 24.0, "x1": 852.0, "y1": 9.0, "z1": 9.0}, {"x0": 0.0, "y0": 0.0, "z0": 24.0, "x1": 852.0, "y1": 10.0, "z1": 56.0}, {"x0": 0.0, "y0": 0.0, "z0": 24.0, "x1": 1430.0, "y1": 14.0, "z1": 10.0}, {"x0": 0.0, "y0": 0.0, "z0": 24.0, "x1": 1644.0, "y1": 15.0, "z1": 48.0}, {"x0": 365.0, "y0": 1.0, "z0": 2.0, "x1": 610.0, "y1": 4.0, "z1": 47.0}, {"x0": 487.0, "y0": 2.0, "z0": 4.0, "x1": 730.0, "y1": 5.0, "z1": 42.0}, {"x0": 487.0, "y0": 2.0, "z0": 4.0, "x1": 760.0, "y1": 6.0, "z1": 39.0}, {"x0": 487.0, "y0": 2.0, "z0": 4.0, "x1": 822.0, "y1": 8.0, "z1": 40.0}, {"x0": 487.0, "y0": 2.0, "z0": 4.0, "x1": 1004.0, "y1": 11.0, "z1": 45.0}, {"x0": 579.0, "y0": 3.0, "z0": 49.0, "x1": 730.0, "y1": 5.0, "z1": 42.0}, {"x0": 610.0, "y0": 4.0, "z0": 47.0, "x1": 791.0, "y1": 7.0, "z1": 34.0}, {"x0": 610.0, "y0": 4.0, "z0": 47.0, "x1": 1065.0, "y1": 12.0, "z1": 0.0}, {"x0": 791.0, "y0": 7.0, "z0": 34.0, "x1": 1856.0, "y1": 22.0, "z1": 36.0}, {"x0": 852.0, "y0": 10.0, "z0": 56.0, "x1": 1310.0, "y1": 13.0, "z1": 53.0}, {"x0": 852.0, "y0": 10.0, "z0": 56.0, "x1": 1795.0, "y1": 20.0, "z1": 31.0}, {"x0": 1065.0, "y0": 12.0, "z0": 0.0, "x1": 1675.0, "y1": 17.0, "z1": 44.0}, {"x0": 1065.0, "y0": 12.0, "z0": 0.0, "x1": 1795.0, "y1": 21.0, "z1": 46.0}, {"x0": 1065.0, "y0": 12.0, "z0": 0.0, "x1": 1856.0, "y1": 22.0, "z1": 36.0}, {"x0": 1065.0, "y0": 12.0, "z0": 0.0, "x1": 2099.0, "y1": 25.0, "z1": 27.0}, {"x0": 1310.0, "y0": 13.0, "z0": 53.0, "x1": 1644.0, "y1": 16.0, "z1": 19.0}, {"x0": 1430.0, "y0": 14.0, "z0": 10.0, "x1": 1765.0, "y1": 19.0, "z1": 41.0}, {"x0": 1644.0, "y0": 15.0, "z0": 48.0, "x1": 1734.0, "y1": 18.0, "z1": 8.0}, {"x0": 1675.0, "y0": 17.0, "z0": 44.0, "x1": 2009.0, "y1": 23.0, "z1": 50.0}, {"x0": 1734.0, "y0": 18.0, "z0": 8.0, "x1": 2071.0, "y1": 24.0, "z1": 12.0}, {"x0": 1734.0, "y0": 18.0, "z0": 8.0, "x1": 2099.0, "y1": 25.0, "z1": 27.0}, {"x0": 1734.0, "y0": 18.0, "z0": 8.0, "x1": 2252.0, "y1": 32.0, "z1": 6.0}, {"x0": 1734.0, "y0": 18.0, "z0": 8.0, "x1": 2283.0, "y1": 33.0, "z1": 51.0}, {"x0": 1765.0, "y0": 19.0, "z0": 41.0, "x1": 2436.0, "y1": 40.0, "z1": 32.0}, {"x0": 2009.0, "y0": 23.0, "z0": 50.0, "x1": 2099.0, "y1": 26.0, "z1": 1.0}, {"x0": 2071.0, "y0": 24.0, "z0": 12.0, "x1": 2191.0, "y1": 27.0, "z1": 5.0}, {"x0": 2071.0, "y0": 24.0, "z0": 12.0, "x1": 2221.0, "y1": 29.0, "z1": 38.0}, {"x0": 2071.0, "y0": 24.0, "z0": 12.0, "x1": 2221.0, "y1": 30.0, "z1": 58.0}, {"x0": 2071.0, "y0": 24.0, "z0": 12.0, "x1": 2252.0, "y1": 32.0, "z1": 6.0}, {"x0": 2071.0, "y0": 24.0, "z0": 12.0, "x1": 2283.0, "y1": 33.0, "z1": 51.0}, {"x0": 2071.0, "y0": 24.0, "z0": 12.0, "x1": 2649.0, "y1": 49.0, "z1": 54.0}, {"x0": 2099.0, "y0": 25.0, "z0": 27.0, "x1": 2526.0, "y1": 45.0, "z1": 60.0}, {"x0": 2099.0, "y0": 26.0, "z0": 1.0, "x1": 2221.0, "y1": 28.0, "z1": 13.0}, {"x0": 2099.0, "y0": 26.0, "z0": 1.0, "x1": 2252.0, "y1": 31.0, "z1": 28.0}, {"x0": 2191.0, "y0": 27.0, "z0": 5.0, "x1": 2283.0, "y1": 34.0, "z1": 22.0}, {"x0": 2221.0, "y0": 28.0, "z0": 13.0, "x1": 2344.0, "y1": 35.0, "z1": 20.0}, {"x0": 2221.0, "y0": 29.0, "z0": 38.0, "x1": 2344.0, "y1": 36.0, "z1": 3.0}, {"x0": 2221.0, "y0": 29.0, "z0": 38.0, "x1": 2496.0, "y1": 44.0, "z1": 57.0}, {"x0": 2221.0, "y0": 30.0, "z0": 58.0, "x1": 2405.0, "y1": 38.0, "z1": 25.0}, {"x0": 2252.0, "y0": 32.0, "z0": 6.0, "x1": 2557.0, "y1": 47.0, "z1": 7.0}, {"x0": 2283.0, "y0": 33.0, "z0": 51.0, "x1": 2374.0, "y1": 37.0, "z1": 52.0}, {"x0": 2283.0, "y0": 34.0, "z0": 22.0, "x1": 2405.0, "y1": 39.0, "z1": 11.0}, {"x0": 2344.0, "y0": 35.0, "z0": 20.0, "x1": 2465.0, "y1": 41.0, "z1": 15.0}, {"x0": 2344.0, "y0": 35.0, "z0": 20.0, "x1": 2465.0, "y1": 42.0, "z1": 30.0}, {"x0": 2344.0, "y0": 35.0, "z0": 20.0, "x1": 2465.0, "y1": 43.0, "z1": 17.0}, {"x0": 2465.0, "y0": 41.0, "z0": 15.0, "x1": 2679.0, "y1": 50.0, "z1": 16.0}, {"x0": 2465.0, "y0": 42.0, "z0": 30.0, "x1": 2557.0, "y1": 46.0, "z1": 23.0}, {"x0": 2465.0, "y0": 43.0, "z0": 17.0, "x1": 2891.0, "y1": 57.0, "z1": 18.0}, {"x0": 2496.0, "y0": 44.0, "z0": 57.0, "x1": 2587.0, "y1": 48.0, "z1": 35.0}, {"x0": 2526.0, "y0": 45.0, "z0": 60.0, "x1": 2983.0, "y1": 58.0, "z1": 37.0}, {"x0": 2557.0, "y0": 46.0, "z0": 23.0, "x1": 2802.0, "y1": 54.0, "z1": 29.0}, {"x0": 2557.0, "y0": 47.0, "z0": 7.0, "x1": 2771.0, "y1": 52.0, "z1": 14.0}, {"x0": 2649.0, "y0": 49.0, "z0": 54.0, "x1": 2740.0, "y1": 51.0, "z1": 59.0}, {"x0": 2740.0, "y0": 51.0, "z0": 59.0, "x1": 2771.0, "y1": 53.0, "z1": 43.0}, {"x0": 2771.0, "y0": 52.0, "z0": 14.0, "x1": 2861.0, "y1": 55.0, "z1": 33.0}, {"x0": 2802.0, "y0": 54.0, "z0": 29.0, "x1": 2891.0, "y1": 56.0, "z1": 55.0}, {"x0": 2891.0, "y0": 56.0, "z0": 55.0, "x1": 3014.0, "y1": 60.0, "z1": 21.0}, {"x0": 2891.0, "y0": 57.0, "z0": 18.0, "x1": 2983.0, "y1": 59.0, "z1": 26.0}], "axis_labels": {"x": "Time (days since Jun 2017)", "y": "Model (chronological index)", "z": "Technical innovation"}, "axis_limits": {"x": [-150.70000000000002, 3164.7], "y": [-3.0, 63.0], "z": [-3.0, 63.0]}, "categories": {"models": [{"index": 0, "label": "Attention Is All You Need"}, {"index": 1, "label": "GPT-1"}, {"index": 2, "label": "BERT"}, {"index": 3, "label": "Transformer-XL"}, {"index": 4, "label": "GPT-2"}, {"index": 5, "label": "XLNet"}, {"index": 6, "label": "RoBERTa"}, {"index": 7, "label": "Megatron-LM"}, {"index": 8, "label": "ALBERT"}, {"index": 9, "label": "BART"}, {"index": 10, "label": "T5"}, {"index": 11, "label": "ELECTRA"}, {"index": 12, "label": "GPT-3"}, {"index": 13, "label": "Switch Transformer"}, {"index": 14, "label": "LaMDA"}, {"index": 15, "label": "Gopher"}, {"index": 16, "label": "GLaM"}, {"index": 17, "label": "InstructGPT"}, {"index": 18, "label": "Chinchilla"}, {"index": 19, "label": "PaLM"}, {"index": 20, "label": "UL2"}, {"index": 21, "label": "OPT"}, {"index": 22, "label": "BLOOM"}, {"index": 23, "label": "Constitutional AI"}, {"index": 24, "label": "LLaMA"}, {"index": 25, "label": "GPT-4"}, {"index": 26, "label": "Claude 1"}, {"index": 27, "label": "Baichuan-7B"}, {"index": 28, "label": "Claude 2"}, {"index": 29, "label": "Llama 2"}, {"index": 30, "label": "InternLM-7B"}, {"index": 31, "label": "Claude Instant 1.2"}, {"index": 32, "label": "Qwen 7B"}, {"index": 33, "label": "Mistral 7B"}, {"index": 34, "label": "Baichuan2"}, {"index": 35, "label": "Claude 2.1"}, {"index": 36, "label": "Yi-34B"}, {"index": 37, "label": "Mixtral 8x7B"}, {"index": 38, "label": "InternLM2-7B"}, {"index": 39, "label": "Baichuan3"}, {"index": 40, "label": "Gemini 1.5"}, {"index": 41, "label": "Claude 3 Haiku"}, {"index": 42, "label": "Claude 3 Sonnet"}, {"index": 43, "label": "Claude 3 Opus"}, {"index": 44, "label": "Llama 3"}, {"index": 45, "label": "GPT-4o"}, {"index": 46, "label": "Claude 3.5 Sonnet"}, {"index": 47, "label": "Qwen2"}, {"index": 48, "label": "Llama 3.1"}, {"index": 49, "label": "DeepSeek-V2.5"}, {"index": 50, "label": "Claude 3.5 Haiku"}, {"index": 51, "label": "DeepSeek-V3"}, {"index": 52, "label": "Qwen2.5 (Max)"}, {"index": 53, "label": "DeepSeek-R1"}, {"index": 54, "label": "Claude 3.7 Sonnet"}, {"index": 55, "label": "Qwen3"}, {"index": 56, "label": "Claude 4 Sonnet"}, {"index": 57, "label": "Claude 4 Opus"}, {"index": 58, "label": "GPT-5"}, {"index": 59, "label": "Claude Opus 4.1"}, {"index": 60, "label": "Claude 4.5 Sonnet"}], "innovations": [{"index": 0, "label": "175B parameter scaling with in-context learning across diverse tasks"}, {"index": 1, "label": "Applied constitutional AI feedback to align helpful and harmless behaviour"}, {"index": 2, "label": "Applied decoder-only Transformer with generative pretraining on BooksCorpus"}, {"index": 3, "label": "Balanced bilingual dataset with progressive context extension"}, {"index": 4, "label": "Bidirectional encoder pretraining with masked language modelling and next sentence prediction"}, {"index": 5, "label": "Chinese-English bilingual adaptation of LLaMA with extended vocabulary"}, {"index": 6, "label": "Chinese-English foundation with rotary embeddings and fine-grained tokeniser"}, {"index": 7, "label": "Data mixture refresh with extended context and reasoning tuning"}, {"index": 8, "label": "Data/parameter scaling law balancing showing benefits of more tokens over parameters"}, {"index": 9, "label": "Denoising autoencoder that bridges encoder-decoder pretraining for text generation"}, {"index": 10, "label": "Dialogue-optimised training with safety fine-tuning and grounded responses"}, {"index": 11, "label": "Domain-adaptive pretraining with knowledge-augmented decoding"}, {"index": 12, "label": "Efficient scaling via smaller datasets, grouped-query attention, and open research weights"}, {"index": 13, "label": "Expanded context and constitutional alignment refinements with tool use"}, {"index": 14, "label": "Expanded multilingual coverage with large context generalisation"}, {"index": 15, "label": "Fast multimodal assistant with revised constitutional tuning"}, {"index": 16, "label": "Faster multimodal responses with improved grounding"}, {"index": 17, "label": "Flagship Claude with state-of-the-art reasoning and coding alignment"}, {"index": 18, "label": "Frontier reasoning with multi-agent constitutional guidance"}, {"index": 19, "label": "Hierarchical mixture-of-experts with token-level routing across 1.2T parameters"}, {"index": 20, "label": "Higher factual reliability and longer context for enterprise tasks"}, {"index": 21, "label": "Hybrid symbolic-neural planning with compressed memory"}, {"index": 22, "label": "Improved bilingual data curation with extended context and tool APIs"}, {"index": 23, "label": "Improved tool-use reliability and creative reasoning"}, {"index": 24, "label": "Introduced the Transformer architecture with multi-head self-attention and positional encoding"}, {"index": 25, "label": "Iterative distillation with modular tool-using skills and expanded context"}, {"index": 26, "label": "Iterative self-improvement through agentic evaluation loops"}, {"index": 27, "label": "Large multimodal alignment with reinforced fine-tuning and tool integration"}, {"index": 28, "label": "Latency-optimised Claude variant retaining constitutional safety guarantees"}, {"index": 29, "label": "Long-context orchestration and improved agentic behaviours"}, {"index": 30, "label": "Mid-tier multimodal reasoning with tool orchestration"}, {"index": 31, "label": "Mixture-of-denoisers objective supporting multiple corruption schemes for unified learning"}, {"index": 32, "label": "Mixture-of-experts multimodal model with million-token context"}, {"index": 33, "label": "Mixture-of-experts scaling with automated reasoning curriculum"}, {"index": 34, "label": "Model parallelism for trillion-parameter scale using tensor and pipeline parallelism"}, {"index": 35, "label": "Multi-token prediction and improved tool-calling APIs"}, {"index": 36, "label": "Multilingual open-access 176B parameter model trained collaboratively via Megatron-DeepSpeed"}, {"index": 37, "label": "Next-generation multimodal orchestration with autonomous tool chains"}, {"index": 38, "label": "Open-weight release with supervised fine-tuning and RLHF safety tuning"}, {"index": 39, "label": "Optimised masked language modelling with longer training, dynamic masking, and larger batches"}, {"index": 40, "label": "Parameter sharing and factorised embeddings for lightweight bidirectional transformers"}, {"index": 41, "label": "Pathways system with parallelism and chain-of-thought prompting across 540B parameters"}, {"index": 42, "label": "Permuted language modelling objective blending autoregressive and autoencoding pretraining"}, {"index": 43, "label": "Reinforced reasoning with reward models targeting mathematical proofs"}, {"index": 44, "label": "Reinforcement learning from human feedback tailored to instruction following"}, {"index": 45, "label": "Replaced masked language modelling with discriminator that detects replaced tokens"}, {"index": 46, "label": "Reproducible GPT-3 class model with fully documented training pipeline"}, {"index": 47, "label": "Scaled decoder-only models with zero-shot transfer via WebText"}, {"index": 48, "label": "Scaling laws with retrieval-style evaluation and precision study for large transformers"}, {"index": 49, "label": "Segment-level recurrence and relative positional encoding for long-context modelling"}, {"index": 50, "label": "Self-critiquing alignment loop guided by explicit normative principles"}, {"index": 51, "label": "Sliding window attention and grouped-query attention for efficient small models"}, {"index": 52, "label": "Sparse mixture-of-experts combining eight Mistral experts with router training"}, {"index": 53, "label": "Sparse mixture-of-experts routing enabling trillion-parameter efficiency"}, {"index": 54, "label": "Sparse mixture-of-experts with hybrid reinforcement learning"}, {"index": 55, "label": "Structured tool-use planning with autonomous memory"}, {"index": 56, "label": "Text-to-Text framework with unified transfer learning and span-corruption objective"}, {"index": 57, "label": "Token-efficient vocabulary and speculatively decoded training mix"}, {"index": 58, "label": "Toolkit-oriented Chinese open model with multi-stage pretraining and alignment"}, {"index": 59, "label": "Unified MoE and dense experts with reinforcement fine-tuning"}, {"index": 60, "label": "Unified multimodal end-to-end model with real-time streaming latency"}]}, "legend_items": [{"label": "Alignment", "color": "#1f77b4"}, {"label": "Baichuan", "color": "#aec7e8"}, {"label": "Claude", "color": "#ff7f0e"}, {"label": "DeepMind/Scaling", "color": "#ffbb78"}, {"label": "DeepSeek", "color": "#2ca02c"}, {"label": "Encoder-only", "color": "#98df8a"}, {"label": "GPT", "color": "#d62728"}, {"label": "Google", "color": "#ff9896"}, {"label": "InternLM", "color": "#9467bd"}, {"label": "LLaMA", "color": "#c5b0d5"}, {"label": "Long-context", "color": "#8c564b"}, {"label": "Mistral", "color": "#c49c94"}, {"label": "Mixture-of-Experts", "color": "#e377c2"}, {"label": "Open-Source GPT", "color": "#f7b6d2"}, {"label": "Qwen", "color": "#7f7f7f"}, {"label": "Root", "color": "#c7c7c7"}, {"label": "Scaling", "color": "#bcbd22"}, {"label": "Seq2Seq", "color": "#dbdb8d"}, {"label": "Yi", "color": "#17becf"}], "point_size": 16.0, "background_color": "#05070d", "instructions": "Drag to rotate \u2022 Scroll to zoom \u2022 Hover a node to inspect the model and its links. Panels list the indices used on the model and innovation axes."};
  const CSS_RULES = ".three-phylogeny-container { position: relative; width: 100%; height: 100%; font-family: 'Inter','Helvetica Neue',Arial,sans-serif; }\n.three-phylogeny-overlay { position: absolute; inset: 0; pointer-events: none; color: #f8fafc; }\n.three-phylogeny-tooltip { position: absolute; min-width: 220px; background: rgba(15,23,42,0.92); border: 1px solid rgba(148,163,184,0.35); border-radius: 8px; padding: 12px; font-size: 13px; line-height: 1.4; display: none; pointer-events: none; box-shadow: 0 10px 30px rgba(15,23,42,0.45); backdrop-filter: blur(6px); }\n.three-phylogeny-tooltip-title { font-weight: 600; font-size: 14px; margin-bottom: 6px; color: #e2e8f0; }\n.three-phylogeny-tooltip-row { display: flex; justify-content: space-between; margin-bottom: 4px; gap: 12px; }\n.three-phylogeny-tooltip-row span:first-child { opacity: 0.75; }\n.three-phylogeny-axis-panel { position: absolute; bottom: 20px; left: 20px; padding: 12px 16px; border-radius: 10px; background: rgba(15,23,42,0.72); border: 1px solid rgba(148,163,184,0.35); backdrop-filter: blur(6px); box-shadow: 0 8px 25px rgba(15,23,42,0.35); pointer-events: auto; max-width: 360px; font-size: 13px; line-height: 1.5; }\n.three-phylogeny-axis-row { display: flex; justify-content: space-between; margin-bottom: 4px; gap: 12px; }\n.three-phylogeny-axis-row span:last-child { font-weight: 600; }\n.three-phylogeny-legend { position: absolute; top: 20px; left: 20px; display: grid; grid-template-columns: repeat(2, minmax(140px, 1fr)); gap: 8px 14px; padding: 14px 16px; background: rgba(15,23,42,0.72); border-radius: 12px; border: 1px solid rgba(148,163,184,0.35); box-shadow: 0 8px 25px rgba(15,23,42,0.35); backdrop-filter: blur(6px); pointer-events: auto; }\n.three-phylogeny-legend-item { display: flex; align-items: center; gap: 10px; font-size: 13px; color: #e2e8f0; }\n.three-phylogeny-swatch { width: 14px; height: 14px; border-radius: 50%; box-shadow: 0 2px 8px rgba(15,23,42,0.45); border: 1px solid rgba(15,23,42,0.4); display: inline-block; }\n.three-phylogeny-categories { position: absolute; right: 20px; top: 20px; display: grid; gap: 12px; width: min(320px, 28%); pointer-events: auto; }\n.three-phylogeny-category { background: rgba(15,23,42,0.72); border-radius: 12px; border: 1px solid rgba(148,163,184,0.35); padding: 14px 16px; backdrop-filter: blur(6px); box-shadow: 0 8px 25px rgba(15,23,42,0.35); max-height: 240px; overflow-y: auto; font-size: 12.5px; line-height: 1.5; }\n.three-phylogeny-category h3 { margin: 0 0 8px; font-size: 13px; letter-spacing: 0.01em; text-transform: uppercase; opacity: 0.8; }\n.three-phylogeny-category ul { margin: 0; padding-left: 18px; }\n.three-phylogeny-category li { margin-bottom: 4px; }\n.three-phylogeny-instructions { position: absolute; right: 20px; bottom: 20px; padding: 12px 16px; border-radius: 12px; background: rgba(15,23,42,0.72); border: 1px solid rgba(148,163,184,0.35); backdrop-filter: blur(6px); font-size: 13px; max-width: min(360px, 40%); box-shadow: 0 8px 25px rgba(15,23,42,0.35); pointer-events: auto; }\n.three-phylogeny-error { position: absolute; inset: 0; display: flex; align-items: center; justify-content: center; color: #f8fafc; font-size: 16px; background: rgba(15,23,42,0.9); border-radius: 12px; }";
  const TARGET_ID = 'three-phylogeny-61a1376911a9415f91efca16daf4b784';

  function waitForHost() {
    return new Promise((resolve) => {
      let attempts = 0;
      function check() {
        const host = document.querySelector('[data-root-id] .bk-Div');
        if (host) {
          resolve(host);
          return;
        }
        attempts += 1;
        if (attempts > 200) {
          console.error('Three.js host element not found');
          resolve(null);
          return;
        }
        requestAnimationFrame(check);
      }
      check();
    });
  }

  waitForHost().then((host) => {
    if (!host) {
      return;
    }

    let container = document.getElementById(TARGET_ID);
    if (!container) {
      container = document.createElement('div');
      container.id = TARGET_ID;
      container.className = 'three-phylogeny-container';
      container.style.width = '100%';
      container.style.height = '100%';
      host.innerHTML = '';
      host.appendChild(container);
    }

    if (!document.getElementById('three-phylogeny-style')) {
      const style = document.createElement('style');
      style.id = 'three-phylogeny-style';
      style.textContent = CSS_RULES;
      document.head.appendChild(style);
    }

    function loadScript(url) {
    return new Promise((resolve, reject) => {
      const existing = Array.from(document.getElementsByTagName('script')).find((el) => el.src === url);
      if (existing) {
        if (existing.dataset.loaded === 'true') {
          resolve();
        } else {
          const handle = () => { existing.dataset.loaded = 'true'; resolve(); };
          existing.addEventListener('load', handle, {once: true});
          existing.addEventListener('error', () => reject(new Error('Failed to load ' + url)), {once: true});
        }
        return;
      }
      const script = document.createElement('script');
      script.src = url;
      script.dataset.loaded = 'false';
      script.addEventListener('load', () => { script.dataset.loaded = 'true'; resolve(); }, {once: true});
      script.addEventListener('error', () => reject(new Error('Failed to load ' + url)), {once: true});
      document.head.appendChild(script);
    });
  }

    const ensureThree = loadScript('assets/three.min.js');
    ensureThree
      .then(() => loadScript('assets/OrbitControls.js'))
      .then(init)
      .catch((err) => {
        container.innerHTML = '<div class="three-phylogeny-error">Unable to load 3D resources. See console for details.</div>';
        console.error(err);
      });

  function init() {
    if (!(window.THREE && window.THREE.OrbitControls)) {
      console.error('Three.js resources missing');
      container.innerHTML = '<div class="three-phylogeny-error">Three.js resources missing.</div>';
      return;
    }

    container.innerHTML = '';
    const renderer = new THREE.WebGLRenderer({antialias: true});
    renderer.setPixelRatio(window.devicePixelRatio || 1);
    container.appendChild(renderer.domElement);

    const scene = new THREE.Scene();
    scene.background = new THREE.Color(CONFIG.background_color || '#05070d');

    const camera = new THREE.PerspectiveCamera(45, 1, 0.1, 10000);
    const controls = new THREE.OrbitControls(camera, renderer.domElement);
    controls.enableDamping = true;
    controls.dampingFactor = 0.08;

    const ambient = new THREE.AmbientLight(0xffffff, 0.65);
    scene.add(ambient);
    const directional = new THREE.DirectionalLight(0xffffff, 0.65);
    directional.position.set(1.2, 1.6, 2.4);
    scene.add(directional);

    const overlay = document.createElement('div');
    overlay.className = 'three-phylogeny-overlay';
    container.appendChild(overlay);

    const tooltip = document.createElement('div');
    tooltip.className = 'three-phylogeny-tooltip';
    overlay.appendChild(tooltip);

    const axisPanel = document.createElement('div');
    axisPanel.className = 'three-phylogeny-axis-panel';
    overlay.appendChild(axisPanel);

    ['x','y','z'].forEach((key) => {
      const row = document.createElement('div');
      row.className = 'three-phylogeny-axis-row';
      const label = document.createElement('span');
      label.textContent = CONFIG.axis_labels?.[key] || key.toUpperCase();
      const span = document.createElement('span');
      const limits = CONFIG.axis_limits?.[key] || [];
      span.textContent = limits.map((value) => Number(value).toFixed(1)).join(' â†’ ');
      row.appendChild(label);
      row.appendChild(span);
      axisPanel.appendChild(row);
    });

    const legend = document.createElement('div');
    legend.className = 'three-phylogeny-legend';
    (CONFIG.legend_items || []).forEach((item) => {
      const entry = document.createElement('div');
      entry.className = 'three-phylogeny-legend-item';
      entry.innerHTML = `<span class="three-phylogeny-swatch" style="background:${item.color || '#ffffff'}"></span><span>${item.label || ''}</span>`;
      legend.appendChild(entry);
    });
    overlay.appendChild(legend);

    const categoryWrap = document.createElement('div');
    categoryWrap.className = 'three-phylogeny-categories';
    overlay.appendChild(categoryWrap);

    function buildCategory(key, title) {
      const data = CONFIG.categories?.[key] || [];
      if (!Array.isArray(data) || data.length === 0)
        return;
      const panel = document.createElement('div');
      panel.className = 'three-phylogeny-category';
      const heading = document.createElement('h3');
      heading.textContent = title;
      panel.appendChild(heading);
      const list = document.createElement('ul');
      data.forEach((entry) => {
        const item = document.createElement('li');
        item.textContent = `${entry.index}: ${entry.label}`;
        list.appendChild(item);
      });
      panel.appendChild(list);
      categoryWrap.appendChild(panel);
    }

    buildCategory('models', 'Model index');
    buildCategory('innovations', 'Innovation index');

    if (CONFIG.instructions) {
      const instructions = document.createElement('div');
      instructions.className = 'three-phylogeny-instructions';
      instructions.textContent = CONFIG.instructions;
      overlay.appendChild(instructions);
    }

    const raycaster = new THREE.Raycaster();
    const mouse = new THREE.Vector2();

    const nodeData = CONFIG.data || {};
    const count = (nodeData.x || []).length;
    const positions = new Float32Array(count * 3);
    const colors = new Float32Array(count * 3);
    for (let i = 0; i < count; i++) {
      positions[i * 3] = Number(nodeData.x?.[i] ?? 0);
      positions[i * 3 + 1] = Number(nodeData.y?.[i] ?? 0);
      positions[i * 3 + 2] = Number(nodeData.z?.[i] ?? 0);
      const color = new THREE.Color(nodeData.color?.[i] || '#ffffff');
      colors[i * 3] = color.r;
      colors[i * 3 + 1] = color.g;
      colors[i * 3 + 2] = color.b;
    }

    const pointGeometry = new THREE.BufferGeometry();
    pointGeometry.setAttribute('position', new THREE.Float32BufferAttribute(positions, 3));
    pointGeometry.setAttribute('color', new THREE.Float32BufferAttribute(colors, 3));
    const pointMaterial = new THREE.PointsMaterial({size: CONFIG.point_size || 16, vertexColors: true, sizeAttenuation: true});
    const points = new THREE.Points(pointGeometry, pointMaterial);
    scene.add(points);

    const edges = CONFIG.edges || [];
    if (edges.length > 0) {
      const edgePositions = new Float32Array(edges.length * 6);
      edges.forEach((edge, index) => {
        edgePositions[index * 6] = Number(edge.x0 ?? 0);
        edgePositions[index * 6 + 1] = Number(edge.y0 ?? 0);
        edgePositions[index * 6 + 2] = Number(edge.z0 ?? 0);
        edgePositions[index * 6 + 3] = Number(edge.x1 ?? 0);
        edgePositions[index * 6 + 4] = Number(edge.y1 ?? 0);
        edgePositions[index * 6 + 5] = Number(edge.z1 ?? 0);
      });
      const edgeGeometry = new THREE.BufferGeometry();
      edgeGeometry.setAttribute('position', new THREE.Float32BufferAttribute(edgePositions, 3));
      const edgeMaterial = new THREE.LineBasicMaterial({color: 0x8891a7, transparent: true, opacity: 0.35});
      const edgeLines = new THREE.LineSegments(edgeGeometry, edgeMaterial);
      scene.add(edgeLines);
    }

    const limits = CONFIG.axis_limits || {};
    const xLimits = limits.x || [0, 1];
    const yLimits = limits.y || [0, 1];
    const zLimits = limits.z || [0, 1];
    const origin = new THREE.Vector3(xLimits[0], yLimits[0], zLimits[0]);
    const axisGroup = new THREE.Group();
    const axisDefs = [
      {dir: new THREE.Vector3(xLimits[1] - xLimits[0], 0, 0), color: 0xff6b6b},
      {dir: new THREE.Vector3(0, yLimits[1] - yLimits[0], 0), color: 0x4ecdc4},
      {dir: new THREE.Vector3(0, 0, zLimits[1] - zLimits[0]), color: 0x1a8cff},
    ];
    axisDefs.forEach((axis) => {
      const geom = new THREE.BufferGeometry().setFromPoints([
        origin,
        origin.clone().add(axis.dir),
      ]);
      axisGroup.add(new THREE.Line(geom, new THREE.LineBasicMaterial({color: axis.color})));
    });
    scene.add(axisGroup);

    function showTooltip(index, event) {
      const name = nodeData.name?.[index] ?? '';
      const family = nodeData.family?.[index] ?? '';
      const release = nodeData.release?.[index] ?? '';
      const innovation = nodeData.innovation?.[index] ?? '';
      const influences = nodeData.influences?.[index] ?? 'None';
      tooltip.innerHTML = `
        <div class="three-phylogeny-tooltip-title">${name}</div>
        <div class="three-phylogeny-tooltip-row"><span>Family</span><span>${family}</span></div>
        <div class="three-phylogeny-tooltip-row"><span>Released</span><span>${release}</span></div>
        <div class="three-phylogeny-tooltip-row"><span>Innovation</span><span>${innovation}</span></div>
        <div class="three-phylogeny-tooltip-row"><span>Influences</span><span>${influences}</span></div>
      `;
      const rect = renderer.domElement.getBoundingClientRect();
      const left = event.clientX - rect.left + 14;
      const top = event.clientY - rect.top + 14;
      tooltip.style.left = `${left}px`;
      tooltip.style.top = `${top}px`;
      tooltip.style.display = 'block';
    }

    function hideTooltip() {
      tooltip.style.display = 'none';
    }

    function onPointerMove(event) {
      const rect = renderer.domElement.getBoundingClientRect();
      mouse.x = ((event.clientX - rect.left) / rect.width) * 2 - 1;
      mouse.y = -(((event.clientY - rect.top) / rect.height) * 2 - 1);
      raycaster.setFromCamera(mouse, camera);
      const intersections = raycaster.intersectObject(points);
      if (intersections.length > 0 && intersections[0].index != null) {
        showTooltip(intersections[0].index, event);
      } else {
        hideTooltip();
      }
    }

    renderer.domElement.addEventListener('mousemove', onPointerMove);
    renderer.domElement.addEventListener('mouseleave', hideTooltip);

    function resize() {
      const viewWidth = container.clientWidth || 1200;
      const viewHeight = container.clientHeight || 800;
      renderer.setSize(viewWidth, viewHeight, false);
      camera.aspect = viewWidth / viewHeight;
      camera.updateProjectionMatrix();
    }

    window.addEventListener('resize', resize);
    resize();

    const spanX = xLimits[1] - xLimits[0];
    const spanY = yLimits[1] - yLimits[0];
    const spanZ = zLimits[1] - zLimits[0];
    const maxSpan = Math.max(spanX, spanY, spanZ, 1);
    camera.position.set(origin.x + spanX * 0.6, origin.y + spanY * 0.5, origin.z + maxSpan * 2.2);
    controls.target.copy(origin.clone().add(new THREE.Vector3(spanX / 2, spanY / 2, spanZ / 2)));

    function renderLoop() {
      requestAnimationFrame(renderLoop);
      controls.update();
      renderer.render(scene, camera);
    }

    renderLoop();
  }
  });
})();

</script>
</body>
</html>